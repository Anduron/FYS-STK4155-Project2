%================================================================
\section{Theory}\label{sec:Theory}
%================================================================

%----------------------------------------------------------------
\subsection{The Ising Model}\label{sec:ising theory}
%----------------------------------------------------------------
The Ising model is a binary value system where the variables of the model can take two values only, e.g. $\pm 1$ or 0 and 1. In statistical mechanics, the Ising model is used to model interacting magnetic dipole moments of atomic spins. The spins, denoted by $s$, are are arranged in a lattice with $L$ spin sites, allowing each spin to interact with its neighbors. The two dimensional square lattice Ising model exhibits a phase transition from a magnetic phase(a system with finite magnetic moment) to a phase with zero magnetization at a given critical temperature, called the Curie temperature, $T_C$. \cite{PROJising}

By simplifying the interaction between the spins to nearest neighbors only and assuming that the nearest neighbors have the same interaction strength, the Hamiltonian of the system can be defined as
\begin{equation}\label{eq:ising energy}
    H = - J \sum_{\ev{kl}} s_k s_l,
\end{equation}
where the spins $s=\pm 1$, $\ev{kl}$ indicates that the sum is over the nearest neighbors only, $J$ is a coupling constant expressing the strength of the interaction between neighboring spins. 

For $J>0$ it is energetically favorable for neighboring spins to be aligned, and the magnetic system will have a ferromagnetic ordering. Ferromagnetic materials exhibit a long-range ordering phenomenon where a given magnetic moment, through interactions between nearest neighbors, can influence the alignment of spins that are separated from the given spin by a macroscopic distance.
At temperatures below the Curie temperature, $T_C$, the ordering of spin states lead to a phenomenon called spontaneous magnetization. That is, the lattice has a net magnetization even in the absence of an external magnetic field. For temperatures $T\geq T_C$, however, the ferromagnetic property disappears as a result of thermal agitation. \cite{PROJising}

In the regression part of this study, we will consider the one-dimensional Ising model with nearest neighbor interactions on a chain of length $N$ with periodic boundary conditions, that is, spins at the boundary will have its nearest neighbors at the opposite boundary. In one-dimension \autoref{eq:ising energy} reduces to 

\begin{equation}\label{eq:ising 1D energy}
    H  = - J \sum_{j=1}^N s_j s_{j+1},
\end{equation}

This model does not exhibit any phase transition at finite temperature.



%----------------------------------------------------------------
\subsection{Linear Regression (revisited)}\label{sec:linreg theory}
%----------------------------------------------------------------
Linear regression is used to predict the value of a continuous dependent variable by simply computing a weighted sum of the input features. A study of three regression methods, namely, Ordinary Least Squares (OLS), Ridge, and Least Absolute Shrinkage and Selection Operator (Lasso), were carried out by the authors in \cite{PROJone}. For a detailed discussion of the aforementioned regression methods, as well as the mean squared error (MSE), coefficient of determination ($R^2$ score), bias and variance, please consult \autoref{sec:Appendix A} or \cite{PROJone}.

%--------------------------------------------------------------
\subsection{Logistic Regression}\label{sec:logreg theory}
%--------------------------------------------------------------
Some regression algorithms can be used for classification




%%%%%%%%%%%%%%%%%%%%%%%%%%%
Motivate

logistic function

MLE - cross-entropy

binary - general?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Logistic regression can be used to classify instances into different classes by modelling the probability of a certain class or event existing e.g. win/lose, 1/0 etc. 

We look at the case of two classes, positive and negative, corresponding to the outputs $y=1$ and $y=0$.

\textbf{The Sigmoid Function}

In linear regression the output is the weighted sum of inputs. In logistic regression the output is not the weighted sum directly, we rather pass it through an \textit{activation function} that can map any real value between 0 and 1. The activation function is known as the \textit{sigmoid} (or \textit{logit}) function, and is given by

\begin{equation}\label{eq:sigmoid_func}
    \sigma (t) = \frac{1}{1+ e^{-t}}
\end{equation}

\autoref{fig:logistic}

\begin{figure}[H]
\begin{center}\includegraphics[scale=0.6]{latex/figures/logistic_function.pdf}
\end{center}
\caption{Logistic}
\label{fig:logistic}
\end{figure}

As seen in the figure, the value of the sigmoid function always lies between 0 and 1. The value is exactly 0.5 at $t=0$. Thus, 0.5 can be used as the probability threshold, $p$, to determine the classes. If $p \geq 0.5$ the instance $t$ belongs to the positive class ($y = 1$), or else we classify it as the negative class ($y = 0$).

\textbf{The Logistic Regression Model}

A linear regression model can be represented by

\begin{equation}
    y = \beta^T X
\end{equation}

The logistic regression models estimated probability is then

\begin{equation}
    \hat{p} = \sigma (\beta^T X),
\end{equation}

and the logistic regression model prediction is hence

\begin{equation}
\hat{y} = \begin{cases} 0 \quad \text{if } \hat{p} < 0.5 \\ 1 \quad \text{if } \hat{p} \geq 0.5 \end{cases} 
\end{equation}

\textbf{The Cost Function}

Like for linear regression, we define a cost for our model and the objective will be to minimize the cost.

The cost function of a single training instance can be given by

\begin{equation}
    C(\beta) = \begin{cases} - \log(\hat{p}) &\quad \text{if } y=1 \\ - \log(1-\hat{p}) &\quad \text{if } y=0  \end{cases}
\end{equation}

To show that this cost function makes sense, we plot a simplified version with $t=\beta^T X$ below.

\autoref{fig:logistic_cost}

\begin{figure}[H]
\begin{center}\includegraphics[scale=0.6]{latex/figures/logistic_cost_func.pdf}
\end{center}
\caption{Logistic cost}
\label{fig:logistic_cost}
\end{figure}

The objective of the cost function is to heavily penalize the model if it predicts a negative class ($y=0$) if the actual class is positive ($y=1$) and vice-versa. 

As seen in the above figure, for $C(\beta) = - \log(\hat{p})$ the cost nears 0 as $\hat{p}$ approaches 1 and as $\hat{p}$ nears 0 the cost goes toward infinity (that is, we penalize the model heavily). Similarly, for $C(\beta) = - \log(1 - \hat{p})$, when the actual value is 0 and the model predicts 0, the cost is 0, and the cost goes toward infinity as $\hat{p}$ approaches 1.


%--------------------------------------------------------------
\subsection{Optimization and Gradient Methods}\label{sec:optim theory}
%--------------------------------------------------------------

\subsubsection{Gradient Descent}\label{sec:gradient descent}
Let $f\colon U\to\mathbb{R}$ be a function defined on a subset of $\mathbb{R}^n$. Suppose that $x\in U$ and that $f$ is differentiable in $x_0$. Then from the point $x_0$, the function $f$ has the steepest decrease in the direction along $-\nabla f(x_0)$. Hence, unless $x_0$ gives a minimum for $f$, given $\gamma_0 > 0$ small enough, we have that for $x_1 = x_0 - \gamma_0\nabla f(x_0)$, the inequality $f(x_1)\le f(x_0)$ holds. For all $n\in\mathbb{N}$, define
\begin{equation*}
    x_n = x_{n-1} - \gamma_{n-1}\nabla f(x_{n-1}),
\end{equation*}
where $\gamma_{n-1}>0$ is some number. If the $\gamma_{n}$ are chosen sufficiently small, the sequence $\{x_n\}_{n\in\mathbb{N}}$ converges to a local minimum. Larger $\gamma_{n}$ make the convergence faster.

\subsubsection{Newton-Raphson method}\label{sec:newton-raphson method}

This section is based on \cite[Section 5.6]{FVA}.

Let $A\subseteq\mathbb{R}^n$ and suppose that $f\colon A \to\mathbb{R}^n$ is a differentiable function. If $x_0\in A$, then for $x\in A$ “close” to $x_0$, the function $x\mapsto f(x_0)+Df(x_0)(x-x_0)$ is a good approximation of $f$. Assume that $f$ has a zero close to $x_0$. To try and find this zero, instead of solving $f(x)=0$, we solve the system of linear equations given by
\begin{equation*}
  f(x_0)+Df(x_0)(x-x_0) = 0.
\end{equation*}
If $Df(x_0)$ is invertible, we get the solution
\begin{equation*}
  x_1=x_0-(Df(x_0))^{-1}f(x_0).
\end{equation*}
We can hope that $x_1$ is even closer than $x_0$ to the actual zero of $f$. Repeating the process with $x_1$ instead of $x_0$, we find a new approximation
\begin{equation*}
  x_2=x_1-(Df(x_1))^{-1}f(x_1).
\end{equation*}
If we continue this for all $n\in\mathbb{N}$, we get a sequence $\{x_n\}_{n\in\mathbb{N}}$ where
\begin{equation*}
  x_n=x_{n-1}-(Df(x_{n-1}))^{-1}f(x_{n-1}).
\end{equation*}
Hopefully the sequence converges to a point $x=\lim_{n\to\infty}$ such that $f(x)=0$. This root-finding algorithm is called the \emph{Newton-Raphson method}.

In general Newton-Raphson is not guaranteed to work. Sufficient conditions are given in the Kantorovich theorem:
\begin{theorem}
  Let $f\colon U\to\mathbb{R}^n$ be a differentiable function defined on an open convex subset $U$ of $\mathbb{R}^n$. Assume that the Jacobian $Df$ of $f$ is Lipschitz continuous on $U$, i.e. that there exists an element $M\in\mathbb{R}$ such that
  \begin{equation*}
    \norm{Df(x)-Df(y)}\le M\norm{x-y}
  \end{equation*}
  for any $x,y\in U$.

Let $x_0\in U$ and suppose that $Df(x_0)$ is invertible. Find a number $K$ with $\norm{Df(x_0)^{-1}}\le K$, and assume that the closed ball $B\left(x_0,\frac{1}{KM}\right)$, with center in $x_0$ and radius $\frac{1}{KM}$ is contained in $U$. If
\begin{equation*}
  \norm{x_1-x_0}=\norm{Df(x_0)^{-1}f(x_0)}\le\frac{1}{2KM},
\end{equation*}
then $Df(x)$ is invertible for all $x$ in the open ball $B\left(x,\frac{1}{KM}\right)$. If we start Newton-Raphson in $x_0$, then all the points $x_n$ are contained in $B\left(x_0,\frac{1}{KM}\right)$ and the limit $x=\lim_{n\to\infty}x_n$ exists and satisfies $f(x)=0$.
\end{theorem}

%----------------------------------------------------------------
\subsection{Neural Network}\label{sec:dnn theory}
%----------------------------------------------------------------
Neural networks comprise a huge family of flexible function suitable of approximating nearly any function. Originally used as a simple model of the brain 
by McCulloch and Pitts in 1943(Siter), the field of neural networks has proved to be extremely useful in the world of modelling and machine learning. Today, the progress is still going strong, with application in a vast number of fields and many different flavors of neural networks

\subsubsection{Architechture of the Feed-Forward Neural Network}
In this project, we focus on the feed-forward neural network, hereafter referred
to simply as neural network. A neural network is in essence a real-valued function that may take number of inputs and outputs. It's behaviour is completely determined by its architecture, which is comprised of hidden layers.

A hidden layers is a set of nodes that relates to the emitted values of the 
previous hidden layer, or the inputs, it case it is the first hidden layer in the 
network. For the i'th node in the first hidden layer, its activation is 
calculated as
\begin{equation}\label{eq:activation}
    z^1_i = \sum_{j=1}^N W^1_{ij}x_j + b^1_j,
\end{equation}
where $N$ is the number of inputs $x$, $W^1$ is a matrix of the weights connecting the inputs to the first hidden layer, and $b^1$ is a constant bias term added to the activation. Taking the activation as the output of the first hidden layer, \autoref{eq:activation} defines a method of feeding information to the next hidden layer as well, and ultimately through the entire network. However, it can easily be seen from the equation that the feeding of information from one layer to another is a affine transformation. Since a affine transformation of a affine transformation is a affine transformation in itself, adding more layers to a network fails in making a more complex model. To avoid this collapse of 
layers, we need to introduce a non-linear function $f^1$ to the activation before 
passing it to the next layer
\begin{equation}\label{eq:non_linear}
    a^1_i = f^1(z^1_i)
\end{equation}

Non-linear functions used are typically sigmoid, $\tanh$ or the Relu, and enables neural network of becoming powerful and flexible models.

\subsubsection{Backward Propagation}
To evaluate how good a neural network performs on data, some kind of 
cost function is consulted

\begin{equation}\label{eq:cost}
    C(y, \tilde{y}) = \sum_{i=1}^N c(y_i, \tilde{y_i}) 
\end{equation}
Where the sum is over $N$ data-points, $y_i$ is the target of the i'th data point,
and $\tilde{y_i}$ is the accompanying prediction of the network given by $\tilde{y_i} = NN(X_i)$. $c$ is typically he square loss for regression

\begin{equation}\label{eq:square_loss}
    c(y_i, \tilde{y_i}) = (y_i - \tilde{y_i})^2,
\end{equation}

and cross entropy for binary classification
\begin{equation}\label{eq:square_loss}
    c(y_i, \tilde{y_i}) = y_i\log(\tilde{y_i}) + (1 - y_i)\log(1 - \tilde{y_i}),
\end{equation}

For a untrained neural network, the weights $W$ connecting all the layers are typically initialized in random fashion, popularly as $W \sim N(0,1)$, and the biases $b$ set to a small number such as $0.01$. 

To improve the model from the initial random state, we would like to minimize the cost function with respect to the weights. As the neural network is a very complex function, and not even a convex problem where are minima are global minema, the optimal weights can not be found by $\frac{dC}{dW^l_{ij}} = 0$. Instead, we resort to using gradient decent methods.
