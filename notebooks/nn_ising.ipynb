{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks for regression and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set fontsizes in figures\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'axes.labelsize': 'large',\n",
    "          'axes.titlesize': 'large',\n",
    "          'xtick.labelsize': 'large',\n",
    "          'ytick.labelsize': 'large',\n",
    "          'legend.fontsize': 'large',\n",
    "          'legend.handlelength': 2}\n",
    "plt.rcParams.update(params)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import code from src\n",
    "sys.path.insert(0, '../src/')\n",
    "from project_tools import fig_path\n",
    "\n",
    "from neuralnetwork import *\n",
    "from isingmodel import generate_1Ddata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data for 1D Ising-model energy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "np.random.seed(42)\n",
    "L = 40     # system size\n",
    "N = 10000  # number of points\n",
    "data, target = generate_1Ddata(L, N)\n",
    "\n",
    "max_val = np.max(target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, train_size=0.96, test_size=0.04)\n",
    "\n",
    "#independent validation set\n",
    "X_val, y_val = generate_1Ddata(L, 1000)\n",
    "\n",
    "#normalize target\n",
    "y_train /= max_val\n",
    "y_test /= max_val\n",
    "y_val /= max_val\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search for neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(y, y_pred):\n",
    "    y_mean = np.mean(y)\n",
    "    return 1 - np.sum((y - y_pred)**2) /np.sum((y - y_mean)**2)\n",
    "\n",
    "def accuracy(y, y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    return np.mean(y == y_pred)\n",
    "\n",
    "def grid_search_nn(learning_rate, penalty, layers, activ_func, cost, \n",
    "                   batch_size, epochs, X_train, y_train, X_val, y_val, accuracy):\n",
    "    count = 0\n",
    "    tot_steps = len(learning_rate)*len(penalty)\n",
    "\n",
    "    models = []\n",
    "    #training models\n",
    "    for lr in learning_rate:\n",
    "        for p in penalty:\n",
    "            count += 1\n",
    "            \n",
    "            models.append(NeuralNetwork(layers, activ_func, cost))\n",
    "            models[-1].train(X_train, y_train, X_val, y_val, lr, p, batch_size, epochs, accuracy)\n",
    "            \n",
    "\n",
    "            sys.stdout.write(\"\\r\" + \"%d/%d\"%(count, tot_steps))\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify neural network for regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanh = Tanh()\n",
    "sig = Sigmoid()\n",
    "relu = Relu()\n",
    "_pass = Pass()\n",
    "square_loss = SquareLoss()\n",
    "np.random.seed(42)\n",
    "\n",
    "layers = [1600, 400, 1]\n",
    "activ_func = [tanh, _pass]\n",
    "cost = square_loss\n",
    "\n",
    "#learning_rate = [1e-5, 4e-5, 9e-5]\n",
    "#penalty =       [1e-5, 1e-4, 1e-3]\n",
    "\n",
    "learning_rate = [7e-5, 9e-5, 1.1e-4]\n",
    "penalty =       [5e-4, 1e-3, 2e-3]\n",
    "\n",
    "models = grid_search_nn(learning_rate, penalty, layers, activ_func, cost, 100, 50, X_train, y_train, X_val, y_val, R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot R2-score of the various models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x,y,data,title=None):\n",
    "\n",
    "    # plot results\n",
    "    fontsize=16\n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(data, interpolation='nearest', vmin=0, vmax=1)\n",
    "    \n",
    "    cbar=fig.colorbar(cax)\n",
    "    cbar.ax.set_ylabel('accuracy (%)',rotation=90,fontsize=fontsize)\n",
    "    cbar.set_ticks([0,.2,.4,0.6,0.8,1.0])\n",
    "    cbar.set_ticklabels(['0%','20%','40%','60%','80%','100%'])\n",
    "\n",
    "    # put text on matrix elements\n",
    "    for i, x_val in enumerate(np.arange(len(x))):\n",
    "        for j, y_val in enumerate(np.arange(len(y))):\n",
    "            c = \"${0:.1f}\\\\%$\".format( 100*data[j,i])  \n",
    "            ax.text(x_val, y_val, c, va='center', ha='center')\n",
    "\n",
    "    # convert axis vaues to to string labels\n",
    "    x=[str(i) for i in x]\n",
    "    y=[str(i) for i in y]\n",
    "\n",
    "\n",
    "    ax.set_xticklabels(['']+x)\n",
    "    ax.set_yticklabels(['']+y)\n",
    "\n",
    "    ax.set_xlabel('$\\\\mathrm{learning\\\\ rate}$',fontsize=fontsize)\n",
    "    ax.set_ylabel('$\\\\mathrm{penalty}$',fontsize=fontsize)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_train = []\n",
    "R2_test = []\n",
    "for i in range(len(models)):\n",
    "    y_pred = models[i].predict(X_train)[:,0]\n",
    "    R2_train.append(R2(y_train, y_pred)) \n",
    "    \n",
    "    y_pred = models[i].predict(X_test)[:,0]\n",
    "    R2_test.append(R2(y_test, y_pred))\n",
    "    \n",
    "R2_train = np.array(R2_train).reshape((3,3))\n",
    "R2_test = np.array(R2_test).reshape((3,3))\n",
    "\n",
    "plot_data(learning_rate, penalty, R2_train, title = \"train\")\n",
    "plot_data(learning_rate, penalty, R2_test, title = \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the connection strength of various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_connection_strength(model):\n",
    "    connection_strength = np.sum(np.abs(model.W[0]),axis = 0)\n",
    "    ave_cs = np.mean(connection_strength)*np.ones(len(connection_strength))\n",
    "\n",
    "    explanatory_weights = np.array(list(range(1, 1600, 41)) + list(range(40, 1600, 41)))\n",
    "    ave_ew = np.mean(connection_strength[explanatory_weights])*np.ones(len(explanatory_weights))\n",
    "\n",
    "    plt.plot(connection_strength, \"b-\", alpha=0.5, label = \"Connection Strength (CS)\")\n",
    "    plt.plot(ave_cs,\"b-\", lw = 3, label = \"_no_legend\")\n",
    "    plt.plot(explanatory_weights, connection_strength[explanatory_weights], \n",
    "            \"ro\", label = \"CS of Contributing Features\", alpha = 0.8)\n",
    "    plt.plot(explanatory_weights, ave_ew, \"r-\", lw = 3, label = \"_no_legend\")\n",
    "    plt.legend(loc = \"lower left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(R2_test))   \n",
    "best_model = models[np.argmax(R2_test)]\n",
    "worst_model = models[np.argmin(R2_test)]\n",
    "\n",
    "plot_connection_strength(models[1])\n",
    "plot_connection_strength(models[4])\n",
    "plot_connection_strength(models[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional (over-penalized) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate2 = [9e-5]\n",
    "penalty2 =       [3e-3]\n",
    "\n",
    "over_penalized = grid_search_nn(learning_rate2, penalty2, layers, activ_func, cost, 100, 50, X_train, y_train, X_val, y_val, R2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_connection_strength(over_penalized)\n",
    "\n",
    "y_pred = over_penalized.predict(X_test)[:,0]\n",
    "print(\"R2-score: \",R2(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the learning progress of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_learning(models, learning_rate, penalty):\n",
    "    for i in range(len(models)):\n",
    "        plt.plot(models[i].acc_train[10:])\n",
    "    \n",
    "    plt.title(\"Penalty = %s\"%penalty)\n",
    "    leg = [\"R2-score on test, $\\\\mu$ = %s\"%lr for lr in learning_rate]\n",
    "    plt.legend(leg)\n",
    "    \n",
    "\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning(models[0:3], learning_rate, penalty[0])\n",
    "plot_learning(models[3:6], learning_rate, penalty[1])\n",
    "plot_learning(models[6:9], learning_rate, penalty[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data and save locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_main = \"https://physics.bu.edu/~pankajm/ML-Review-Datasets/isingMC/\"\n",
    "data_file_name = \"Ising2DFM_reSample_L40_T=All.pkl\"\n",
    "label_file_name = \"Ising2DFM_reSample_L40_T=All_labels.pkl\"\n",
    "\n",
    "labels = pickle.load(urlopen(url_main + label_file_name))\n",
    "\n",
    "data = pickle.load(urlopen(url_main + data_file_name))\n",
    "data = np.unpackbits(data).reshape(-1, 1600)\n",
    "data = data.astype('int')\n",
    "\n",
    "np.save(\"labels\", labels)\n",
    "np.save(\"spin_data\", data)\n",
    "\n",
    "del data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"spin_data.npy\")\n",
    "y = np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# divide data into ordered, critical and disordered\n",
    "X_ordered=X[:70000,:]\n",
    "y_ordered=y[:70000]\n",
    "\n",
    "X_critical=X[70000:100000,:]\n",
    "y_critical=y[70000:100000]\n",
    "\n",
    "X_disordered=X[100000:,:]\n",
    "y_disordered=y[100000:]\n",
    "\n",
    "# Remove critical, since we only want to train on ordered and disorderes\n",
    "X=np.concatenate((X_ordered,X_disordered))\n",
    "y=np.concatenate((y_ordered,y_disordered))\n",
    "\n",
    "# pick random data points from ordered and disordered states \n",
    "# to create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.4, test_size=0.1)\n",
    "X_train, X_val, y_train, y_val =   train_test_split(X_train, y_train, train_size=0.75,test_size=0.25)\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state(data):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(data, interpolation='nearest')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_state(X_ordered[0].reshape(40,40))\n",
    "plot_state(X_disordered[0].reshape(40,40))\n",
    "plot_state(X_critical[0].reshape(40,40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the neural network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanh = Tanh()\n",
    "sig = Sigmoid()\n",
    "relu = Relu()\n",
    "cross_entropy = CrossEntropy()\n",
    "\n",
    "layers = [1600, 400, 1]\n",
    "activ_func = [sig, sig]\n",
    "cost = cross_entropy\n",
    "\n",
    "learning_rate = [0.00001, 0.00002, 0.00003]\n",
    "penalty =       [0.00001, 0.0001, 0.001]\n",
    "\n",
    "np.random.seed(42)\n",
    "models = grid_search_nn(learning_rate, penalty, layers, activ_func, cost, 100, 50, \n",
    "                        X_train, y_train, X_val, y_val, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = []\n",
    "acc_test = []\n",
    "acc_crit = []\n",
    "for i in range(len(models)):\n",
    "    y_pred = models[i].predict(X_train)[:,0]\n",
    "    acc_train.append(accuracy(y_train, y_pred)) \n",
    "    \n",
    "    y_pred = models[i].predict(X_test)[:,0]\n",
    "    acc_test.append(accuracy(y_test, y_pred))\n",
    "    \n",
    "    y_pred = models[i].predict(X_critical)[:,0]\n",
    "    acc_crit.append(accuracy(y_critical, y_pred))\n",
    "    \n",
    "acc_train = np.array(acc_train).reshape((3,3))\n",
    "acc_test = np.array(acc_test).reshape((3,3))\n",
    "acc_crit = np.array(acc_crit).reshape((3,3))\n",
    "\n",
    "plot_data(learning_rate, penalty, acc_train, title = \"train\")\n",
    "plot_data(learning_rate, penalty, acc_test, title = \"test\")\n",
    "plot_data(learning_rate, penalty, acc_crit, title = \"crit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[np.argmax(acc_crit)]\n",
    "\n",
    "y_pred = np.round(best_model.predict(X_critical))[:,0]\n",
    "\n",
    "wrong_pred = X_critical[(y_critical != y_pred)]\n",
    "wrong_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_state(wrong_pred[0].reshape(40,40))\n",
    "plot_state(wrong_pred[1].reshape(40,40))\n",
    "plot_state(wrong_pred[2].reshape(40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
